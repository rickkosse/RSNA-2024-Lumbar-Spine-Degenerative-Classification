{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":71549,"databundleVersionId":8561470,"sourceType":"competition"},{"sourceId":128928,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":108621,"modelId":132938}],"dockerImageVersionId":30775,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pydicom\nimport numpy as np\nimport cv2\nimport torch\nfrom torch.utils.data import Dataset\nimport os\nimport glob\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom collections import OrderedDict\nfrom sklearn.model_selection import KFold\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-10-07T11:42:58.096312Z","iopub.execute_input":"2024-10-07T11:42:58.096726Z","iopub.status.idle":"2024-10-07T11:42:58.103047Z","shell.execute_reply.started":"2024-10-07T11:42:58.096685Z","shell.execute_reply":"2024-10-07T11:42:58.101841Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"\n# Basisdirectory waar alle DICOM-afbeeldingen zijn opgeslagen\nroot_dir = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_images'\n\n# Lijst om alle DICOM-bestandspaden op te slaan\ndicom_paths = []\n\n# Loop door alle subdirectories (study_id en series_id)\nfor study_dir in os.listdir(root_dir):\n    study_path = os.path.join(root_dir, study_dir)\n    \n    if os.path.isdir(study_path):\n        for series_dir in os.listdir(study_path):\n            series_path = os.path.join(study_path, series_dir)\n            \n            if os.path.isdir(series_path):\n                # Zoek naar alle .dcm-bestanden in deze serie-directory\n                dicom_files = glob.glob(os.path.join(series_path, '*.dcm'))\n                \n                # Voeg elk DICOM-bestandspad toe aan de dicom_paths-lijst\n                dicom_paths.extend(dicom_files)\n\n# Controleer het aantal gevonden DICOM-bestanden\nprint(f'Aantal gevonden DICOM-bestanden: {len(dicom_paths)}')\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-07T11:42:58.398738Z","iopub.execute_input":"2024-10-07T11:42:58.399162Z","iopub.status.idle":"2024-10-07T11:43:42.761624Z","shell.execute_reply.started":"2024-10-07T11:42:58.399097Z","shell.execute_reply":"2024-10-07T11:43:42.760525Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Aantal gevonden DICOM-bestanden: 147218\n","output_type":"stream"}]},{"cell_type":"code","source":"class SegmentationDataset(Dataset):\n    def __init__(self, dicom_paths, coords_dict, target_size=(512, 512), transform=None):\n        self.dicom_paths = dicom_paths\n        self.coords_dict = coords_dict\n        self.target_size = target_size\n        self.transform = transform\n\n    def __getitem__(self, idx):\n        dicom_path = self.dicom_paths[idx]\n        \n        # Lees de DICOM-afbeelding\n        dicom_data = pydicom.dcmread(dicom_path)\n        image = dicom_data.pixel_array\n        \n        # Schalen naar [0, 255]\n        image = (image - image.min()) / (image.max() - image.min() + 1e-6) * 255\n\n        # Gebruik cv2.resize om de afbeelding naar de gewenste grootte te schalen\n        image = cv2.resize(image, self.target_size, interpolation=cv2.INTER_CUBIC)\n\n        # Controleer of er coördinaten zijn voor dit pad\n        if dicom_path in self.coords_dict:\n            coords = self.coords_dict[dicom_path]\n            mask = self.generate_mask(image.shape, coords)\n        else:\n            return None  # Sla deze afbeelding over als er geen coördinaten beschikbaar zijn\n\n        # Converteer de afbeelding en het masker naar tensoren\n        image = torch.tensor(image, dtype=torch.float32).unsqueeze(0)  # Voeg een kanaal toe (1-kanaals)\n        mask = torch.tensor(mask, dtype=torch.float32).unsqueeze(0)  # Voeg een kanaal toe (1-kanaals)\n\n        return image, mask\n\n    def generate_mask(self, image_shape, coords):\n        # Genereer een leeg masker\n        mask = np.zeros(image_shape, dtype=np.uint8)\n\n        # Voeg cirkels toe op de coördinaten\n        for (x, y) in coords:\n            cv2.circle(mask, (int(x), int(y)), radius=10, color=255, thickness=-1)\n\n        # Converteer het masker naar binaire waarden (0 of 1)\n        mask = mask / 255.0  # Verdeel door 255 om de waarden te normaliseren naar 0 en 1\n\n        return mask\n\n    def __len__(self):\n        return len(self.dicom_paths)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-07T11:43:42.765359Z","iopub.execute_input":"2024-10-07T11:43:42.765732Z","iopub.status.idle":"2024-10-07T11:43:42.776670Z","shell.execute_reply.started":"2024-10-07T11:43:42.765689Z","shell.execute_reply":"2024-10-07T11:43:42.775512Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def collate_fn(batch):\n    # Verwijder None-items uit de batch\n    batch = [item for item in batch if item is not None]\n    \n    if len(batch) == 0:\n        return None  # Als de batch leeg is, retourneer None\n    \n    return torch.utils.data.default_collate(batch)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-07T11:43:42.778002Z","iopub.execute_input":"2024-10-07T11:43:42.778646Z","iopub.status.idle":"2024-10-07T11:43:42.790773Z","shell.execute_reply.started":"2024-10-07T11:43:42.778607Z","shell.execute_reply":"2024-10-07T11:43:42.789510Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"rd = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification'\ndf = pd.read_csv(f'{rd}/train_series_descriptions.csv')\nst_ids = df['study_id'].unique()\ndfc = pd.read_csv(f'{rd}/train_label_coordinates.csv')\ndesc = list(df['series_description'].unique())","metadata":{"execution":{"iopub.status.busy":"2024-10-07T11:43:42.793410Z","iopub.execute_input":"2024-10-07T11:43:42.794455Z","iopub.status.idle":"2024-10-07T11:43:42.933551Z","shell.execute_reply.started":"2024-10-07T11:43:42.794402Z","shell.execute_reply":"2024-10-07T11:43:42.932408Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"import os\nimport glob\nfrom tqdm import tqdm\n\n# Maak een dictionary aan om de coördinaten op te slaan\ncoords_dict = {}\n\n# Itereer door de rijen in dfc en koppel de coördinaten aan de juiste DICOM afbeelding\nfor idx, row in dfc.iterrows():\n    study_id = row['study_id']\n    series_id = row['series_id']\n    instance_number = row['instance_number']\n    \n    # Zoek de serie beschrijving (series_description) op\n    df_series = df[(df['study_id'] == study_id) & (df['series_id'] == series_id)]\n    \n    if len(df_series) == 0:\n#         print(f\"Geen series_description gevonden voor study_id: {study_id} en series_id: {series_id}\")\n        continue\n    \n    series_desc = df_series['series_description'].values[0]\n    ds_ = series_desc.replace('/', '_')  # Vervang slash om te zorgen dat pad geldig is\n    \n    # Genereer het pad naar de DICOM afbeelding\n    dicom_filename = f'{int(instance_number):01d}.dcm'\n    dicom_path = f'{rd}/train_images/{study_id}/{series_id}/{dicom_filename}'\n    \n    # Controleer of het bestand daadwerkelijk bestaat\n    if os.path.exists(dicom_path):\n        # Coördinaten (x, y)\n        x, y = row['x'], row['y']\n        \n        # Voeg de coördinaat toe aan het corresponderende pad in de coords_dict\n        if dicom_path not in coords_dict:\n            coords_dict[dicom_path] = []\n        \n        coords_dict[dicom_path].append((x, y))\n    else:\n        print(f\"Bestand bestaat niet: {dicom_path}, coördinaten worden overgeslagen.\")\n        continue\n\nprint(f\"Aantal paden in coords_dict: {len(coords_dict)}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-07T11:43:42.934781Z","iopub.execute_input":"2024-10-07T11:43:42.935210Z","iopub.status.idle":"2024-10-07T11:44:34.988011Z","shell.execute_reply.started":"2024-10-07T11:43:42.935165Z","shell.execute_reply":"2024-10-07T11:44:34.986973Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Aantal paden in coords_dict: 24546\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch import nn\n\nclass UNet(nn.Module):\n    def __init__(self, in_channels=3, out_channels=1, init_features=32):\n        super(UNet, self).__init__()\n\n        features = init_features\n        self.encoder1 = UNet._block(in_channels, features, name=\"enc1\")\n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.encoder2 = UNet._block(features, features * 2, name=\"enc2\")\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.encoder3 = UNet._block(features * 2, features * 4, name=\"enc3\")\n        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.encoder4 = UNet._block(features * 4, features * 8, name=\"enc4\")\n        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        self.bottleneck = UNet._block(features * 8, features * 16, name=\"bottleneck\")\n\n        self.upconv4 = nn.ConvTranspose2d(\n            features * 16, features * 8, kernel_size=2, stride=2\n        )\n        self.decoder4 = UNet._block((features * 8) * 2, features * 8, name=\"dec4\")\n        self.upconv3 = nn.ConvTranspose2d(\n            features * 8, features * 4, kernel_size=2, stride=2\n        )\n        self.decoder3 = UNet._block((features * 4) * 2, features * 4, name=\"dec3\")\n        self.upconv2 = nn.ConvTranspose2d(\n            features * 4, features * 2, kernel_size=2, stride=2\n        )\n        self.decoder2 = UNet._block((features * 2) * 2, features * 2, name=\"dec2\")\n        self.upconv1 = nn.ConvTranspose2d(\n            features * 2, features, kernel_size=2, stride=2\n        )\n        self.decoder1 = UNet._block(features * 2, features, name=\"dec1\")\n\n        self.conv = nn.Conv2d(\n            in_channels=features, out_channels=out_channels, kernel_size=1\n        )\n\n    def forward(self, x):\n        enc1 = self.encoder1(x)\n        enc2 = self.encoder2(self.pool1(enc1))\n        enc3 = self.encoder3(self.pool2(enc2))\n        enc4 = self.encoder4(self.pool3(enc3))\n\n        bottleneck = self.bottleneck(self.pool4(enc4))\n\n        dec4 = self.upconv4(bottleneck)\n        dec4 = torch.cat((dec4, enc4), dim=1)\n        dec4 = self.decoder4(dec4)\n\n        dec3 = self.upconv3(dec4)\n        dec3 = torch.cat((dec3, enc3), dim=1)\n        dec3 = self.decoder3(dec3)\n\n        dec2 = self.upconv2(dec3)\n        dec2 = torch.cat((dec2, enc2), dim=1)\n        dec2 = self.decoder2(dec2)\n\n        dec1 = self.upconv1(dec2)\n        dec1 = torch.cat((dec1, enc1), dim=1)\n        dec1 = self.decoder1(dec1)\n\n        return torch.sigmoid(self.conv(dec1))\n\n    @staticmethod\n    def _block(in_channels, features, name):\n        return nn.Sequential(\n            OrderedDict(\n                [\n                    (\n                        f\"{name}_conv1\",\n                        nn.Conv2d(\n                            in_channels=in_channels,\n                            out_channels=features,\n                            kernel_size=3,\n                            padding=1,\n                            bias=False,\n                        ),\n                    ),\n                    (f\"{name}_norm1\", nn.BatchNorm2d(num_features=features)),\n                    (f\"{name}_relu1\", nn.ReLU(inplace=True)),\n                    (\n                        f\"{name}_conv2\",\n                        nn.Conv2d(\n                            in_channels=features,\n                            out_channels=features,\n                            kernel_size=3,\n                            padding=1,\n                            bias=False,\n                        ),\n                    ),\n                    (f\"{name}_norm2\", nn.BatchNorm2d(num_features=features)),\n                    (f\"{name}_relu2\", nn.ReLU(inplace=True)),\n                ]\n            )\n        )","metadata":{"execution":{"iopub.status.busy":"2024-10-07T11:34:26.686987Z","iopub.execute_input":"2024-10-07T11:34:26.687397Z","iopub.status.idle":"2024-10-07T11:34:26.705467Z","shell.execute_reply.started":"2024-10-07T11:34:26.687361Z","shell.execute_reply":"2024-10-07T11:34:26.704401Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-10-07T11:34:38.978074Z","iopub.execute_input":"2024-10-07T11:34:38.978504Z","iopub.status.idle":"2024-10-07T11:34:38.983554Z","shell.execute_reply.started":"2024-10-07T11:34:38.978464Z","shell.execute_reply":"2024-10-07T11:34:38.982452Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\n\nimport os\n\ndef save_checkpoint(model, optimizer, epoch, fold, checkpoint_dir='checkpoints'):\n    \"\"\"Functie om een checkpoint op te slaan.\"\"\"\n    # Controleer of de directory bestaat, en maak deze indien nodig aan\n    os.makedirs(checkpoint_dir, exist_ok=True)\n    \n    # Maak het pad voor de checkpoint met de fold-naam\n    checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_fold_{fold}.pth')  # Correct gebruik van fold in filename\n\n    # Sla het model, optimizer, en epoch op in de checkpoint\n    torch.save({\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'fold': fold\n    }, checkpoint_path)\n    \n    print(f'Checkpoint saved: {checkpoint_path}')\n\n    \ndef load_checkpoint(model, optimizer, fold, checkpoint_dir='checkpoints'):\n    \"\"\"Functie om een checkpoint te laden.\"\"\"\n    # Gebruik de fold-waarde in de bestandsnaam en converteer naar string\n    checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_fold_{fold}.pth')\n    \n    if os.path.exists(checkpoint_path):\n        print(f\"Checkpoint gevonden: {checkpoint_path}\")\n        checkpoint = torch.load(checkpoint_path)\n        \n        # Laad de status van het model en de optimizer\n        model.load_state_dict(checkpoint['model_state_dict'])\n        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n        \n        # Laad het epoch nummer\n        start_epoch = checkpoint['epoch'] + 1\n        print(f\"Hervatten vanaf epoch {start_epoch}\")\n        \n        return start_epoch\n    else:\n        print(f\"Geen checkpoint gevonden in {checkpoint_path}, beginnen vanaf epoch 1.\")\n        return 1  # Start vanaf epoch 1 als er geen checkpoint is","metadata":{"execution":{"iopub.status.busy":"2024-10-07T11:13:07.391451Z","iopub.execute_input":"2024-10-07T11:13:07.392167Z","iopub.status.idle":"2024-10-07T11:13:07.401595Z","shell.execute_reply.started":"2024-10-07T11:13:07.392070Z","shell.execute_reply":"2024-10-07T11:13:07.400453Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# KFold instellen (bijv. 5 folds)\nk_folds = 3\nkf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n\n# dicom_paths en coords_dict bevatten respectievelijk de DICOM-paden en coördinaten\n# dicom_paths: Lijst van paden naar DICOM-bestanden\n# coords_dict: Dictionary met coördinaten voor elke DICOM-bestandspad\n\n# Creëer de folds\ndataset_size = len(dicom_paths)\nindices = list(range(dataset_size))\n\n# Zet de resultaten van alle folds op nul\nresults = {}\n\n# Hyperparameters voor early stopping\nearly_stopping_limit = 3  # Maximaal aantal epochs zonder verbetering\nearly_stopping_patience = early_stopping_limit\n\n# KFold loop\nfor fold, (train_idx, val_idx) in enumerate(kf.split(indices)):\n    print(f'Fold {fold+1}/{k_folds}')\n    \n    # Verdeel dicom_paths in train en validatie sets\n    train_dicom_paths = [dicom_paths[i] for i in train_idx]\n    val_dicom_paths = [dicom_paths[i] for i in val_idx]\n    \n    # Creëer de train en validatie datasets met coords_dict voor het genereren van maskers\n    train_dataset = SegmentationDataset(dicom_paths=train_dicom_paths, coords_dict=coords_dict)\n    val_dataset = SegmentationDataset(dicom_paths=val_dicom_paths, coords_dict=coords_dict)\n    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4, drop_last=True, collate_fn=collate_fn)\n    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4, collate_fn=collate_fn)\n\n    # Instantieer het model\n    model = UNet(in_channels=1, out_channels=1).to(device)  # in_channels aangepast voor grijswaarden DICOM-afbeeldingen\n\n    # Definieer de loss-functie en optimizer\n    criterion = nn.BCELoss()  # Binary Cross-Entropy voor pixel-wise classificatie\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n    \n    # Controleer of er een checkpoint is en hervat de training vanaf dat punt\n    start_epoch = load_checkpoint(model, optimizer, fold)\n    \n    # Training loop\n    num_epochs = 20\n    best_val_loss = float('inf')  # Initieer met een hoge waarde om het beste model op te slaan\n    early_stopping_counter = 0  # Teller voor early stopping\n\n    for epoch in range(start_epoch, num_epochs + 1):\n        model.train()\n        running_loss = 0.0\n    \n        # Trainen\n        for batch in tqdm(train_loader):\n            if batch is None:  # Sla lege batches over\n                continue\n            images, masks = batch\n            images = images.to(device)\n            masks = masks.to(device)\n            # Voorwaartse pass\n            outputs = model(images)\n            loss = criterion(outputs, masks)\n\n            # Achterwaartse pass\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n\n        # Gemiddelde loss van de epoch\n        epoch_loss = running_loss / len(train_loader)\n        print(f'Epoch [{epoch}/{num_epochs}], Train Loss: {epoch_loss:.4f}')\n        \n        # Validatie\n        model.eval()\n        val_loss = 0.0\n        with torch.no_grad():\n            for batch in val_loader:\n                if batch is None:\n                    continue\n                images, masks = batch\n                images = images.to(device)\n                masks = masks.to(device)\n                \n                outputs = model(images)\n                loss = criterion(outputs, masks)\n                val_loss += loss.item()\n        \n        val_loss /= len(val_loader)\n        print(f'Fold {fold+1}, Epoch {epoch}, Validation Loss: {val_loss:.4f}')\n        \n        # Controleer op verbetering van validatie loss\n        if val_loss < best_val_loss:\n            print(f'Saving best model for fold {fold+1}, epoch {epoch}')\n            torch.save(model.state_dict(), f'unet_best_fold_{fold+1}.pth')\n            best_val_loss = val_loss\n            early_stopping_counter = 0  # Reset de early stopping teller\n        else:\n            early_stopping_counter += 1\n            print(f'No improvement for {early_stopping_counter} epochs.')\n        \n        # Opslaan van een checkpoint na elke epoch\n        save_checkpoint(model, optimizer, epoch, fold, checkpoint_dir='checkpoints')\n\n\n        # Controleer of de early stopping limiet is bereikt\n        if early_stopping_counter >= early_stopping_patience:\n            print(f'Early stopping in fold {fold+1} at epoch {epoch}')\n            break  # Verlaat de training loop voor deze fold\n\n    # Sla de resultaten van deze fold op\n    results[fold] = best_val_loss\n\n# Print de resultaten van elke fold\nfor fold in range(k_folds):\n    print(f'Fold {fold+1}: Best Validation Loss: {results[fold]:.4f}')\n\n# Gemiddelde validatie loss over alle folds\navg_val_loss = np.mean([results[fold] for fold in range(k_folds)])\nprint(f'Gemiddelde validatie loss over alle {k_folds} folds: {avg_val_loss:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-10-05T15:19:55.860551Z","iopub.execute_input":"2024-10-05T15:19:55.861330Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Instantieer het model met 1 input channel, wat overeenkomt met het opgeslagen model\nmodel_fold_1 = UNet(in_channels=1, out_channels=1).to(device)\nmodel_fold_2 = UNet(in_channels=1, out_channels=1).to(device)\n\n# Laad de opgeslagen checkpoints van beide folds, map naar CPU\nmodel_fold_1.load_state_dict(torch.load('/kaggle/input/masks_models/pytorch/default/1/unet_best_fold_1 (3).pth', map_location=torch.device('cpu')))\nmodel_fold_2.load_state_dict(torch.load('/kaggle/input/masks_models/pytorch/default/1/unet_best_fold_2.pth', map_location=torch.device('cpu')))\n\n# Zorg ervoor dat het model op het juiste device wordt gezet\nmodel_fold_1.to(device)\nmodel_fold_2.to(device)\n\nmodel_fold_1.eval()\nmodel_fold_2.eval()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-07T11:40:27.715068Z","iopub.execute_input":"2024-10-07T11:40:27.715515Z","iopub.status.idle":"2024-10-07T11:40:28.390455Z","shell.execute_reply.started":"2024-10-07T11:40:27.715473Z","shell.execute_reply":"2024-10-07T11:40:28.389363Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/3936207421.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model_fold_1.load_state_dict(torch.load('/kaggle/input/masks_models/pytorch/default/1/unet_best_fold_1 (3).pth', map_location=torch.device('cpu')))\n/tmp/ipykernel_30/3936207421.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model_fold_2.load_state_dict(torch.load('/kaggle/input/masks_models/pytorch/default/1/unet_best_fold_2.pth', map_location=torch.device('cpu')))\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"UNet(\n  (encoder1): Sequential(\n    (enc1_conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (enc1_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (enc1_relu1): ReLU(inplace=True)\n    (enc1_conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (enc1_norm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (enc1_relu2): ReLU(inplace=True)\n  )\n  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (encoder2): Sequential(\n    (enc2_conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (enc2_norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (enc2_relu1): ReLU(inplace=True)\n    (enc2_conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (enc2_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (enc2_relu2): ReLU(inplace=True)\n  )\n  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (encoder3): Sequential(\n    (enc3_conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (enc3_norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (enc3_relu1): ReLU(inplace=True)\n    (enc3_conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (enc3_norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (enc3_relu2): ReLU(inplace=True)\n  )\n  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (encoder4): Sequential(\n    (enc4_conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (enc4_norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (enc4_relu1): ReLU(inplace=True)\n    (enc4_conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (enc4_norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (enc4_relu2): ReLU(inplace=True)\n  )\n  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (bottleneck): Sequential(\n    (bottleneck_conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bottleneck_norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (bottleneck_relu1): ReLU(inplace=True)\n    (bottleneck_conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bottleneck_norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (bottleneck_relu2): ReLU(inplace=True)\n  )\n  (upconv4): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n  (decoder4): Sequential(\n    (dec4_conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (dec4_norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (dec4_relu1): ReLU(inplace=True)\n    (dec4_conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (dec4_norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (dec4_relu2): ReLU(inplace=True)\n  )\n  (upconv3): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n  (decoder3): Sequential(\n    (dec3_conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (dec3_norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (dec3_relu1): ReLU(inplace=True)\n    (dec3_conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (dec3_norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (dec3_relu2): ReLU(inplace=True)\n  )\n  (upconv2): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n  (decoder2): Sequential(\n    (dec2_conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (dec2_norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (dec2_relu1): ReLU(inplace=True)\n    (dec2_conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (dec2_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (dec2_relu2): ReLU(inplace=True)\n  )\n  (upconv1): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n  (decoder1): Sequential(\n    (dec1_conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (dec1_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (dec1_relu1): ReLU(inplace=True)\n    (dec1_conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (dec1_norm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (dec1_relu2): ReLU(inplace=True)\n  )\n  (conv): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Stel een lijst op van maskers en bijbehorende afbeeldingen\npredicted_masks = []\ntrain_dataset = SegmentationDataset(dicom_paths=dicom_paths, coords_dict=coords_dict)\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4, drop_last=True, collate_fn=collate_fn)\n\nwith torch.no_grad():\n    for batch in tqdm(train_loader):  # Neem de images uit de train_loader of een specifieke loader\n        if batch is None:\n            continue\n        images, masks = batch\n        images = images.to(device)        \n        # Voorspellingen van beide modellen\n        outputs_fold_1 = model_fold_1(images)\n        outputs_fold_2 = model_fold_2(images)\n        \n        # Combineer de voorspellingen (gemiddeld bijvoorbeeld)\n        combined_mask = (outputs_fold_1 + outputs_fold_2) / 2\n        \n        predicted_masks.append(combined_mask.cpu())  # Voeg het gecombineerde masker toe aan de lijst\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-07T11:51:44.058048Z","iopub.execute_input":"2024-10-07T11:51:44.058519Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"  1%|          | 81/9201 [09:00<21:40:43,  8.56s/it]","output_type":"stream"}]}]}